# Repo for the paper

### List of transformers:


BERT - Done


RoBERTa - Done 


DistilBERT - Done


ALBERT - Done


T5 - Done


Ernie (On RobertaBaseCased and BERTBaseCased) and Baseline - Done


XLNet - Done


BERTweet - Done


BigBird - Done


Electra - Done


Longformer - Done (keep it as backup as longformer is mostly used for >1000 token input)


GPT - ( backup )Ashima


Reformer - Discard

