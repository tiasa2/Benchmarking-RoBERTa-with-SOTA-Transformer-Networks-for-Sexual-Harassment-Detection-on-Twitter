{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Longformer_Harassment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c67e1d97d13e4a0797a35959d1f7c309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d5cb1885df84c749062efa10d7dbff1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4980f21b77734e068cb8203dff7700e1",
              "IPY_MODEL_7b9b0d57078847b393c954172dc7c0dc"
            ]
          }
        },
        "2d5cb1885df84c749062efa10d7dbff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4980f21b77734e068cb8203dff7700e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b94116758d64a7393a0cd9f3313bf4c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9f4bf2ad4834257a72ca1800df71429"
          }
        },
        "7b9b0d57078847b393c954172dc7c0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6009626bd96d4c9cbcd856b3cc16cf67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 5.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d474190aa7fb4a01bc04430f9a8f809e"
          }
        },
        "0b94116758d64a7393a0cd9f3313bf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9f4bf2ad4834257a72ca1800df71429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6009626bd96d4c9cbcd856b3cc16cf67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d474190aa7fb4a01bc04430f9a8f809e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d10d5d7ecf2641389f22e32997bf021d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ad51f589bbd46a883081f25f2da78ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_532d8a3b25b64554bb5348cdabc32e00",
              "IPY_MODEL_c4eadd770d3b4f349213016c8485a754"
            ]
          }
        },
        "9ad51f589bbd46a883081f25f2da78ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "532d8a3b25b64554bb5348cdabc32e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8236459d0e64414868b67884fcc113e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e5678dfc39349d0a142bee949dca9f7"
          }
        },
        "c4eadd770d3b4f349213016c8485a754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15619b06c06b4f80ba9491171f68b27c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc9a11d115634d9886d66871b4fb2d04"
          }
        },
        "a8236459d0e64414868b67884fcc113e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e5678dfc39349d0a142bee949dca9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15619b06c06b4f80ba9491171f68b27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc9a11d115634d9886d66871b4fb2d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJebXhqhB7q",
        "outputId": "1d95e248-e122-4821-d82c-74f1b53d45cd"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 32.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 33.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 36.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 25.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 28.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 25.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 26.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 24.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 24.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 48.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 28.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ6UMKaGhMVK"
      },
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SbOk2ZjhOk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d923632-8031-4e47-b26a-387301d90db9"
      },
      "source": [
        "# Setting up GPU\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "print (device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "1oor0Cj2hQyz",
        "outputId": "25296866-067b-407b-f243-464b0702eabd"
      },
      "source": [
        "df = pd.read_csv('Cleaned_tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Key Word</th>\n",
              "      <th>Username</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Favorite_count</th>\n",
              "      <th>Geo</th>\n",
              "      <th>Coordinates</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704</td>\n",
              "      <td>ass</td>\n",
              "      <td>DeborahParr</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 06:56</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>He’d have my phone wedged up his ass sideways.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1915</td>\n",
              "      <td>boobies</td>\n",
              "      <td>MaxZorin85</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 07:35</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Yep 100% agree and the same with severine in s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2856</td>\n",
              "      <td>eat pussy</td>\n",
              "      <td>PRISJ1_</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 10:36</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Stop having sex with men that won’t eat your p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2163</td>\n",
              "      <td>Breast Man</td>\n",
              "      <td>Teresamckenzy1</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>10-11-2020 20:52</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>When you see a sad man, just give him breast t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2852</td>\n",
              "      <td>eat pussy</td>\n",
              "      <td>sj__vazquez</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>11-11-2020 10:42</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>We can't be together if you don't eat pussy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    Key Word        Username  ...  Unnamed: 9 Unnamed: 10  Unnamed: 11\n",
              "0         704         ass     DeborahParr  ...         NaN         NaN          NaN\n",
              "1        1915     boobies      MaxZorin85  ...         NaN         NaN          NaN\n",
              "2        2856   eat pussy         PRISJ1_  ...         NaN         NaN          NaN\n",
              "3        2163  Breast Man  Teresamckenzy1  ...         NaN         NaN          NaN\n",
              "4        2852   eat pussy     sj__vazquez  ...         NaN         NaN          NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "B9BHdSsIhVuN",
        "outputId": "e5ae5a0b-5058-4af7-b364-97e774657607"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Favorite_count</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3604.000000</td>\n",
              "      <td>3.604000e+03</td>\n",
              "      <td>3604.000000</td>\n",
              "      <td>3604.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1801.632908</td>\n",
              "      <td>1.329972e+18</td>\n",
              "      <td>1.429245</td>\n",
              "      <td>0.547447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1040.729184</td>\n",
              "      <td>3.991290e+15</td>\n",
              "      <td>10.752237</td>\n",
              "      <td>0.497813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>900.750000</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1801.500000</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2702.250000</td>\n",
              "      <td>1.330000e+18</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3604.000000</td>\n",
              "      <td>1.350000e+18</td>\n",
              "      <td>396.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0       User_ID  Favorite_count        Label\n",
              "count  3604.000000  3.604000e+03     3604.000000  3604.000000\n",
              "mean   1801.632908  1.329972e+18        1.429245     0.547447\n",
              "std    1040.729184  3.991290e+15       10.752237     0.497813\n",
              "min       0.000000  1.320000e+18        0.000000     0.000000\n",
              "25%     900.750000  1.330000e+18        0.000000     0.000000\n",
              "50%    1801.500000  1.330000e+18        0.000000     1.000000\n",
              "75%    2702.250000  1.330000e+18        1.000000     1.000000\n",
              "max    3604.000000  1.350000e+18      396.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c67e1d97d13e4a0797a35959d1f7c309",
            "2d5cb1885df84c749062efa10d7dbff1",
            "4980f21b77734e068cb8203dff7700e1",
            "7b9b0d57078847b393c954172dc7c0dc",
            "0b94116758d64a7393a0cd9f3313bf4c",
            "c9f4bf2ad4834257a72ca1800df71429",
            "6009626bd96d4c9cbcd856b3cc16cf67",
            "d474190aa7fb4a01bc04430f9a8f809e",
            "d10d5d7ecf2641389f22e32997bf021d",
            "9ad51f589bbd46a883081f25f2da78ce",
            "532d8a3b25b64554bb5348cdabc32e00",
            "c4eadd770d3b4f349213016c8485a754",
            "a8236459d0e64414868b67884fcc113e",
            "8e5678dfc39349d0a142bee949dca9f7",
            "15619b06c06b4f80ba9491171f68b27c",
            "dc9a11d115634d9886d66871b4fb2d04"
          ]
        },
        "id": "I09eJvCVhcJn",
        "outputId": "f7446b71-5fca-4c14-d113-e054ffab89b3"
      },
      "source": [
        "#Preparing Dataset and Dataloader\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "# EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c67e1d97d13e4a0797a35959d1f7c309",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d10d5d7ecf2641389f22e32997bf021d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8lkbc__hoUV"
      },
      "source": [
        "class TweetData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.Text\n",
        "        self.targets = self.data.Label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CVkBjDAhygJ",
        "outputId": "13c370c1-bff1-4089-db8f-ba3408eef34d"
      },
      "source": [
        "train_size = 0.8\n",
        "train_data=df.sample(frac=train_size,random_state=200)\n",
        "test_data=df.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = TweetData(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = TweetData(test_data, tokenizer, MAX_LEN)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (3604, 13)\n",
            "TRAIN Dataset: (2883, 13)\n",
            "TEST Dataset: (721, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWj4V2Jh7ZO"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcqCzmTOh9N2"
      },
      "source": [
        "#Longformer model\n",
        "class LongformerClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LongformerClass, self).__init__()\n",
        "        self.l1 = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 5)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6srQnPth-4m",
        "outputId": "1b77b6b3-7f42-4bad-bdbb-d20d47d45c40"
      },
      "source": [
        "model = LongformerClass()\n",
        "model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerClass(\n",
              "  (l1): LongformerModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): LongformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1WJwqgeiA1b"
      },
      "source": [
        "#Finetuning Longformer model\n",
        "\n",
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvU-ZlDNiJ3l"
      },
      "source": [
        "def calcuate_accuracy(preds, targets):\n",
        "    n_correct = (preds==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9bBf0wniKmU"
      },
      "source": [
        "# Defining the training function on the 80% of the dataset\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        if _%5000==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6uzrRotiN7x",
        "outputId": "fdd4a179-6b5a-4e13-8562-82f382f64340"
      },
      "source": [
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 5000 steps: 1.6314404010772705\n",
            "Training Accuracy per 5000 steps: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "361it [11:04,  1.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 0: 65.10579257717656\n",
            "Training Loss Epoch: 0.6840365506357764\n",
            "Training Accuracy Epoch: 65.10579257717656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkLN2DUJiRLp"
      },
      "source": [
        "#Testing the trained model\n",
        "\n",
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "            \n",
        "            if _%5000==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "    \n",
        "    return epoch_accu\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlQFNO17iw7h",
        "outputId": "8b762e34-38a5-46d7-8b44-86beaf0a54a2"
      },
      "source": [
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  2.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss per 100 steps: 0.791218101978302\n",
            "Validation Accuracy per 100 steps: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "181it [01:13,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss Epoch: 0.49414027725135423\n",
            "Validation Accuracy Epoch: 79.05686546463245\n",
            "Accuracy on test data = 79.06%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KjBRxC2izrq",
        "outputId": "05a08499-4e03-4be0-ffd0-f0b04aeeecdb"
      },
      "source": [
        "output_model_file = 'pytorch_longformer_sentiment.bin'\n",
        "output_vocab_file = './'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./vocab.json', './merges.txt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0vG-iBykSrT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}